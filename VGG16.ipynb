{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIM7TZBaltj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9de6f956-3b7b-478e-e8f3-312e35afb42f"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Concatenate, Dot, Lambda, Input\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "from sklearn import svm\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXZD6_E0l2rm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a656d327-708a-48dd-9f3f-119c09adb444"
      },
      "source": [
        "!pwd\n",
        "#!rm -rf Gestures"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCC4ANyNl63d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "5271ca29-ba64-4701-adb6-2163a88d2b4e"
      },
      "source": [
        "!git clone https://github.com/KuldeepDileep/Gestures.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Gestures'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 29 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OqDPvccmB1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/Gestures/Gestures-Images.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Gestures')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SutfmfiHmGWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "18fb98b5-eb28-4024-c0cc-9a92a6b96e82"
      },
      "source": [
        "TrainDir = '/content/Gestures/Gestures-Images/ASL_Images'\n",
        "\n",
        "count=0\n",
        "current_id = 0\n",
        "label_ids = {}\n",
        "x_train = []\n",
        "y_labels= []\n",
        "\n",
        "image_train = []\n",
        "label_train =[]\n",
        "\n",
        "\n",
        "#---------------------------------------Extracting Train Images-----------------------------------------\n",
        "for root, dirs, files in os.walk(TrainDir):\n",
        "    for file in files:\n",
        "        if file.endswith(\"png\") or  file.endswith(\"jpeg\") or file.endswith(\"jpg\"):\n",
        "            count+=1\n",
        "            path = os.path.join(root, file)\n",
        "            label = os.path.basename(os.path.dirname(path)).replace(\" \",\",\").lower()\n",
        "            label = os.path.basename(root).replace(\" \",\",\").lower()\n",
        "            if not label in label_ids: #if the current label is not in dictionsry we save it with the corresponding current_id i.e 0,1,2\n",
        "                label_ids[label] = current_id\n",
        "                current_id +=1\n",
        "            id_ = label_ids[label]\n",
        "            label_train.append(id_)\n",
        "\n",
        "            \n",
        "            pil_image =  Image.open(path) #Opening the image using Image object and converting it into Gray\n",
        "            pil_image = pil_image.resize((224,224))\n",
        "            pil_image = pil_image.convert(\"RGB\")\n",
        "            image_array =  np.array(pil_image, \"uint8\") #converting the image into a numpy array\n",
        "            image_train.append(image_array)\n",
        "            #print(image_array)\n",
        "print(\"----------------------------Label_ids----------------------------------\")\n",
        "print(label_ids)\n",
        "print(label_ids)\n",
        "print(count)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------Label_ids----------------------------------\n",
            "{'hello': 0, 'my': 1, 'name': 2}\n",
            "{'hello': 0, 'my': 1, 'name': 2}\n",
            "600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RerlKCTvmjjv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6bb3de99-c22b-47df-8c80-76e663445d59"
      },
      "source": [
        "image_train = np.asarray(image_train)\n",
        "label_train = np.asarray(label_train)\n",
        "x_train = image_train\n",
        "y_train = label_train\n",
        "print(image_train[0].shape)\n",
        "print(y_train.shape)\n",
        "print(x_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n",
            "(600,)\n",
            "(600, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtE5lKDSns-8",
        "colab_type": "text"
      },
      "source": [
        "Spliting data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H_HRgsvmuz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d7b901d8-cfc8-4510-d0c4-bd6de7c764ee"
      },
      "source": [
        "#-----------------------------------------------Test and Train Spli--------------------------------------\n",
        "x_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.2)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(480, 224, 224, 3)\n",
            "(120, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk7GgGNPn3dA",
        "colab_type": "text"
      },
      "source": [
        "Data Normalization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaG_qRnRn3Il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train/np.max(x_train)\n",
        "x_test = x_test/np.max(x_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqeSzncLqSJJ",
        "colab_type": "text"
      },
      "source": [
        "One-Hot Encoding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGlx_cZeqRXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCiY9iR5qcUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "13dd4d73-5ae8-4611-a363-d6fe1d0dff39"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(480, 224, 224, 3)\n",
            "(480, 3)\n",
            "(120, 224, 224, 3)\n",
            "(120, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v56rWTpq8RN",
        "colab_type": "text"
      },
      "source": [
        "Convolutional Neural Network (CNN):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnGiXxOdq62_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 500\n",
        "num_classes = 3\n",
        "CNN_model = Sequential()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwhMQz3Voy1b",
        "colab_type": "text"
      },
      "source": [
        "VGG16 (Pretrained CNN based model with 12 layers):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISZYBx55oyT6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "248b9497-b5d0-4d89-fb1d-1aa5a664c41c"
      },
      "source": [
        "vgg16_model = keras.applications.vgg16.VGG16()\n",
        "#vgg16_model = keras.applications.vgg16.VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 1)))\n",
        "vgg16_model.summary()\n",
        "# print(\"#----------------VGG16 Summary-------------#\")\n",
        "for layer in vgg16_model.layers:\n",
        "  CNN_model.add(layer)\n",
        "# print(\"#----------------CNN Summary----------------#\")\n",
        "CNN_model.summary()\n",
        "CNN_model.layers.pop()\n",
        "for layer in CNN_model.layers:\n",
        "  layer.trainable = False     #Freezing layers so that these are not trained\n",
        "CNN_model.add(Dense(num_classes, activation='softmax'))\n",
        "# print(\"#----------------CNN Summary--------#\")\n",
        "CNN_model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 7s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 3003      \n",
            "=================================================================\n",
            "Total params: 138,360,547\n",
            "Trainable params: 3,003\n",
            "Non-trainable params: 138,357,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAD052Byri9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c6e0973-f665-4dc8-a76f-c1ed0b249f6f"
      },
      "source": [
        "CNN_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr = 0.0001),metrics=['accuracy'])\n",
        "history = CNN_model.fit(x_train, y_train,epochs=epochs,verbose=1,validation_data=(x_test, y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 480 samples, validate on 120 samples\n",
            "Epoch 1/500\n",
            "480/480 [==============================] - 17s 35ms/step - loss: 1.0986 - accuracy: 0.3375 - val_loss: 1.0988 - val_accuracy: 0.3167\n",
            "Epoch 2/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0985 - accuracy: 0.3375 - val_loss: 1.0988 - val_accuracy: 0.3167\n",
            "Epoch 3/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0985 - accuracy: 0.3375 - val_loss: 1.0988 - val_accuracy: 0.3167\n",
            "Epoch 4/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0984 - accuracy: 0.3375 - val_loss: 1.0988 - val_accuracy: 0.3167\n",
            "Epoch 5/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0984 - accuracy: 0.3375 - val_loss: 1.0988 - val_accuracy: 0.3167\n",
            "Epoch 6/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0983 - accuracy: 0.3375 - val_loss: 1.0988 - val_accuracy: 0.3167\n",
            "Epoch 7/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0983 - accuracy: 0.3375 - val_loss: 1.0988 - val_accuracy: 0.3167\n",
            "Epoch 8/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0983 - accuracy: 0.3375 - val_loss: 1.0987 - val_accuracy: 0.3167\n",
            "Epoch 9/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0982 - accuracy: 0.3375 - val_loss: 1.0987 - val_accuracy: 0.3167\n",
            "Epoch 10/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0982 - accuracy: 0.3375 - val_loss: 1.0987 - val_accuracy: 0.3167\n",
            "Epoch 11/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0982 - accuracy: 0.3375 - val_loss: 1.0987 - val_accuracy: 0.3167\n",
            "Epoch 12/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0981 - accuracy: 0.3375 - val_loss: 1.0987 - val_accuracy: 0.3167\n",
            "Epoch 13/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0981 - accuracy: 0.3375 - val_loss: 1.0987 - val_accuracy: 0.3167\n",
            "Epoch 14/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0981 - accuracy: 0.3375 - val_loss: 1.0987 - val_accuracy: 0.3167\n",
            "Epoch 15/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0980 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
            "Epoch 16/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0980 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3167\n",
            "Epoch 17/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0980 - accuracy: 0.3896 - val_loss: 1.0986 - val_accuracy: 0.3667\n",
            "Epoch 18/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0979 - accuracy: 0.4667 - val_loss: 1.0986 - val_accuracy: 0.4417\n",
            "Epoch 19/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0979 - accuracy: 0.3979 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 20/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0979 - accuracy: 0.3667 - val_loss: 1.0986 - val_accuracy: 0.3417\n",
            "Epoch 21/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0978 - accuracy: 0.3875 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 22/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0978 - accuracy: 0.5292 - val_loss: 1.0986 - val_accuracy: 0.6000\n",
            "Epoch 23/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0977 - accuracy: 0.6313 - val_loss: 1.0986 - val_accuracy: 0.5917\n",
            "Epoch 24/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0977 - accuracy: 0.5750 - val_loss: 1.0985 - val_accuracy: 0.5500\n",
            "Epoch 25/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0977 - accuracy: 0.5917 - val_loss: 1.0985 - val_accuracy: 0.5750\n",
            "Epoch 26/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0976 - accuracy: 0.6250 - val_loss: 1.0985 - val_accuracy: 0.6000\n",
            "Epoch 27/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0976 - accuracy: 0.6104 - val_loss: 1.0985 - val_accuracy: 0.5500\n",
            "Epoch 28/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0976 - accuracy: 0.6417 - val_loss: 1.0985 - val_accuracy: 0.6167\n",
            "Epoch 29/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0975 - accuracy: 0.6417 - val_loss: 1.0984 - val_accuracy: 0.6000\n",
            "Epoch 30/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0975 - accuracy: 0.6417 - val_loss: 1.0984 - val_accuracy: 0.6250\n",
            "Epoch 31/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0975 - accuracy: 0.6479 - val_loss: 1.0984 - val_accuracy: 0.6167\n",
            "Epoch 32/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0974 - accuracy: 0.6708 - val_loss: 1.0984 - val_accuracy: 0.6250\n",
            "Epoch 33/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0974 - accuracy: 0.6750 - val_loss: 1.0984 - val_accuracy: 0.6250\n",
            "Epoch 34/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0974 - accuracy: 0.6750 - val_loss: 1.0984 - val_accuracy: 0.6250\n",
            "Epoch 35/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0974 - accuracy: 0.6500 - val_loss: 1.0984 - val_accuracy: 0.6083\n",
            "Epoch 36/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0973 - accuracy: 0.6562 - val_loss: 1.0983 - val_accuracy: 0.6250\n",
            "Epoch 37/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0973 - accuracy: 0.6479 - val_loss: 1.0983 - val_accuracy: 0.6083\n",
            "Epoch 38/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0972 - accuracy: 0.6708 - val_loss: 1.0983 - val_accuracy: 0.6250\n",
            "Epoch 39/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0972 - accuracy: 0.6708 - val_loss: 1.0983 - val_accuracy: 0.6250\n",
            "Epoch 40/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0972 - accuracy: 0.6708 - val_loss: 1.0983 - val_accuracy: 0.6250\n",
            "Epoch 41/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0971 - accuracy: 0.6708 - val_loss: 1.0982 - val_accuracy: 0.6250\n",
            "Epoch 42/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0971 - accuracy: 0.6750 - val_loss: 1.0982 - val_accuracy: 0.6250\n",
            "Epoch 43/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0971 - accuracy: 0.6750 - val_loss: 1.0982 - val_accuracy: 0.6250\n",
            "Epoch 44/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0970 - accuracy: 0.6729 - val_loss: 1.0982 - val_accuracy: 0.6250\n",
            "Epoch 45/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0970 - accuracy: 0.6750 - val_loss: 1.0982 - val_accuracy: 0.6250\n",
            "Epoch 46/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0970 - accuracy: 0.6750 - val_loss: 1.0982 - val_accuracy: 0.6250\n",
            "Epoch 47/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0969 - accuracy: 0.6750 - val_loss: 1.0982 - val_accuracy: 0.6250\n",
            "Epoch 48/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0969 - accuracy: 0.6750 - val_loss: 1.0981 - val_accuracy: 0.6250\n",
            "Epoch 49/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0969 - accuracy: 0.6750 - val_loss: 1.0981 - val_accuracy: 0.6250\n",
            "Epoch 50/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0968 - accuracy: 0.6750 - val_loss: 1.0981 - val_accuracy: 0.6250\n",
            "Epoch 51/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0968 - accuracy: 0.6750 - val_loss: 1.0981 - val_accuracy: 0.6250\n",
            "Epoch 52/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0968 - accuracy: 0.6750 - val_loss: 1.0981 - val_accuracy: 0.6167\n",
            "Epoch 53/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0967 - accuracy: 0.6750 - val_loss: 1.0980 - val_accuracy: 0.6250\n",
            "Epoch 54/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0967 - accuracy: 0.6750 - val_loss: 1.0980 - val_accuracy: 0.6250\n",
            "Epoch 55/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0967 - accuracy: 0.6750 - val_loss: 1.0980 - val_accuracy: 0.6250\n",
            "Epoch 56/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0966 - accuracy: 0.6750 - val_loss: 1.0980 - val_accuracy: 0.6250\n",
            "Epoch 57/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0966 - accuracy: 0.6750 - val_loss: 1.0980 - val_accuracy: 0.6167\n",
            "Epoch 58/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0966 - accuracy: 0.6750 - val_loss: 1.0979 - val_accuracy: 0.6250\n",
            "Epoch 59/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0965 - accuracy: 0.6750 - val_loss: 1.0979 - val_accuracy: 0.6250\n",
            "Epoch 60/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0965 - accuracy: 0.6729 - val_loss: 1.0979 - val_accuracy: 0.6167\n",
            "Epoch 61/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0965 - accuracy: 0.6750 - val_loss: 1.0979 - val_accuracy: 0.6250\n",
            "Epoch 62/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0964 - accuracy: 0.6750 - val_loss: 1.0978 - val_accuracy: 0.6167\n",
            "Epoch 63/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0964 - accuracy: 0.6750 - val_loss: 1.0978 - val_accuracy: 0.6250\n",
            "Epoch 64/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0964 - accuracy: 0.6750 - val_loss: 1.0978 - val_accuracy: 0.6250\n",
            "Epoch 65/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0963 - accuracy: 0.6750 - val_loss: 1.0978 - val_accuracy: 0.6250\n",
            "Epoch 66/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0963 - accuracy: 0.6750 - val_loss: 1.0978 - val_accuracy: 0.6250\n",
            "Epoch 67/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0963 - accuracy: 0.6750 - val_loss: 1.0978 - val_accuracy: 0.6250\n",
            "Epoch 68/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0962 - accuracy: 0.6750 - val_loss: 1.0977 - val_accuracy: 0.6250\n",
            "Epoch 69/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0962 - accuracy: 0.6750 - val_loss: 1.0977 - val_accuracy: 0.6167\n",
            "Epoch 70/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0962 - accuracy: 0.6750 - val_loss: 1.0977 - val_accuracy: 0.6250\n",
            "Epoch 71/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0961 - accuracy: 0.6750 - val_loss: 1.0977 - val_accuracy: 0.6167\n",
            "Epoch 72/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0961 - accuracy: 0.6708 - val_loss: 1.0976 - val_accuracy: 0.6167\n",
            "Epoch 73/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0961 - accuracy: 0.6750 - val_loss: 1.0976 - val_accuracy: 0.6167\n",
            "Epoch 74/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0960 - accuracy: 0.6729 - val_loss: 1.0976 - val_accuracy: 0.6167\n",
            "Epoch 75/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0960 - accuracy: 0.6729 - val_loss: 1.0976 - val_accuracy: 0.6167\n",
            "Epoch 76/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0960 - accuracy: 0.6750 - val_loss: 1.0976 - val_accuracy: 0.6250\n",
            "Epoch 77/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0959 - accuracy: 0.6750 - val_loss: 1.0975 - val_accuracy: 0.6167\n",
            "Epoch 78/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0959 - accuracy: 0.6750 - val_loss: 1.0975 - val_accuracy: 0.6250\n",
            "Epoch 79/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0959 - accuracy: 0.6750 - val_loss: 1.0975 - val_accuracy: 0.6250\n",
            "Epoch 80/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0958 - accuracy: 0.6750 - val_loss: 1.0974 - val_accuracy: 0.6167\n",
            "Epoch 81/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0958 - accuracy: 0.6667 - val_loss: 1.0974 - val_accuracy: 0.6167\n",
            "Epoch 82/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0958 - accuracy: 0.6708 - val_loss: 1.0974 - val_accuracy: 0.6250\n",
            "Epoch 83/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0957 - accuracy: 0.6708 - val_loss: 1.0974 - val_accuracy: 0.6167\n",
            "Epoch 84/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0957 - accuracy: 0.6750 - val_loss: 1.0974 - val_accuracy: 0.6250\n",
            "Epoch 85/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0957 - accuracy: 0.6750 - val_loss: 1.0973 - val_accuracy: 0.6167\n",
            "Epoch 86/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0956 - accuracy: 0.6687 - val_loss: 1.0973 - val_accuracy: 0.6167\n",
            "Epoch 87/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0956 - accuracy: 0.6687 - val_loss: 1.0973 - val_accuracy: 0.6167\n",
            "Epoch 88/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0956 - accuracy: 0.6750 - val_loss: 1.0973 - val_accuracy: 0.6167\n",
            "Epoch 89/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0955 - accuracy: 0.6687 - val_loss: 1.0972 - val_accuracy: 0.6167\n",
            "Epoch 90/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0955 - accuracy: 0.6625 - val_loss: 1.0972 - val_accuracy: 0.6167\n",
            "Epoch 91/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0955 - accuracy: 0.6646 - val_loss: 1.0972 - val_accuracy: 0.6167\n",
            "Epoch 92/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0954 - accuracy: 0.6750 - val_loss: 1.0972 - val_accuracy: 0.6167\n",
            "Epoch 93/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0954 - accuracy: 0.6750 - val_loss: 1.0971 - val_accuracy: 0.6167\n",
            "Epoch 94/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0954 - accuracy: 0.6646 - val_loss: 1.0971 - val_accuracy: 0.6167\n",
            "Epoch 95/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0954 - accuracy: 0.6667 - val_loss: 1.0971 - val_accuracy: 0.6167\n",
            "Epoch 96/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0953 - accuracy: 0.6646 - val_loss: 1.0971 - val_accuracy: 0.6167\n",
            "Epoch 97/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0953 - accuracy: 0.6646 - val_loss: 1.0971 - val_accuracy: 0.6167\n",
            "Epoch 98/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0953 - accuracy: 0.6708 - val_loss: 1.0970 - val_accuracy: 0.6167\n",
            "Epoch 99/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0952 - accuracy: 0.6708 - val_loss: 1.0970 - val_accuracy: 0.6167\n",
            "Epoch 100/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0952 - accuracy: 0.6625 - val_loss: 1.0970 - val_accuracy: 0.6167\n",
            "Epoch 101/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0952 - accuracy: 0.6667 - val_loss: 1.0970 - val_accuracy: 0.6167\n",
            "Epoch 102/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0951 - accuracy: 0.6750 - val_loss: 1.0969 - val_accuracy: 0.6250\n",
            "Epoch 103/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0951 - accuracy: 0.6729 - val_loss: 1.0969 - val_accuracy: 0.6167\n",
            "Epoch 104/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0951 - accuracy: 0.6729 - val_loss: 1.0969 - val_accuracy: 0.6167\n",
            "Epoch 105/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0950 - accuracy: 0.6750 - val_loss: 1.0969 - val_accuracy: 0.6250\n",
            "Epoch 106/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0950 - accuracy: 0.6750 - val_loss: 1.0968 - val_accuracy: 0.6167\n",
            "Epoch 107/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0950 - accuracy: 0.6687 - val_loss: 1.0968 - val_accuracy: 0.6167\n",
            "Epoch 108/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0949 - accuracy: 0.6708 - val_loss: 1.0968 - val_accuracy: 0.6250\n",
            "Epoch 109/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0949 - accuracy: 0.6687 - val_loss: 1.0968 - val_accuracy: 0.6167\n",
            "Epoch 110/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0949 - accuracy: 0.6646 - val_loss: 1.0967 - val_accuracy: 0.6167\n",
            "Epoch 111/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0948 - accuracy: 0.6687 - val_loss: 1.0967 - val_accuracy: 0.6167\n",
            "Epoch 112/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0948 - accuracy: 0.6625 - val_loss: 1.0967 - val_accuracy: 0.6167\n",
            "Epoch 113/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0948 - accuracy: 0.6625 - val_loss: 1.0967 - val_accuracy: 0.6167\n",
            "Epoch 114/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0947 - accuracy: 0.6625 - val_loss: 1.0967 - val_accuracy: 0.6167\n",
            "Epoch 115/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0947 - accuracy: 0.6729 - val_loss: 1.0966 - val_accuracy: 0.6167\n",
            "Epoch 116/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0947 - accuracy: 0.6750 - val_loss: 1.0966 - val_accuracy: 0.6167\n",
            "Epoch 117/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0947 - accuracy: 0.6646 - val_loss: 1.0966 - val_accuracy: 0.6167\n",
            "Epoch 118/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0946 - accuracy: 0.6625 - val_loss: 1.0966 - val_accuracy: 0.6167\n",
            "Epoch 119/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0946 - accuracy: 0.6750 - val_loss: 1.0965 - val_accuracy: 0.6250\n",
            "Epoch 120/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0946 - accuracy: 0.6750 - val_loss: 1.0965 - val_accuracy: 0.6167\n",
            "Epoch 121/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0945 - accuracy: 0.6750 - val_loss: 1.0965 - val_accuracy: 0.6167\n",
            "Epoch 122/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0945 - accuracy: 0.6750 - val_loss: 1.0965 - val_accuracy: 0.6167\n",
            "Epoch 123/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0945 - accuracy: 0.6750 - val_loss: 1.0964 - val_accuracy: 0.6250\n",
            "Epoch 124/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0944 - accuracy: 0.6687 - val_loss: 1.0964 - val_accuracy: 0.6167\n",
            "Epoch 125/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0944 - accuracy: 0.6729 - val_loss: 1.0964 - val_accuracy: 0.6250\n",
            "Epoch 126/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0944 - accuracy: 0.6750 - val_loss: 1.0963 - val_accuracy: 0.6250\n",
            "Epoch 127/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0943 - accuracy: 0.6729 - val_loss: 1.0963 - val_accuracy: 0.6167\n",
            "Epoch 128/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0943 - accuracy: 0.6750 - val_loss: 1.0963 - val_accuracy: 0.6250\n",
            "Epoch 129/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0943 - accuracy: 0.6750 - val_loss: 1.0963 - val_accuracy: 0.6250\n",
            "Epoch 130/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0942 - accuracy: 0.6750 - val_loss: 1.0963 - val_accuracy: 0.6167\n",
            "Epoch 131/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0942 - accuracy: 0.6750 - val_loss: 1.0962 - val_accuracy: 0.6167\n",
            "Epoch 132/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0942 - accuracy: 0.6729 - val_loss: 1.0962 - val_accuracy: 0.6167\n",
            "Epoch 133/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0941 - accuracy: 0.6750 - val_loss: 1.0962 - val_accuracy: 0.6167\n",
            "Epoch 134/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0941 - accuracy: 0.6750 - val_loss: 1.0961 - val_accuracy: 0.6167\n",
            "Epoch 135/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0941 - accuracy: 0.6708 - val_loss: 1.0961 - val_accuracy: 0.6167\n",
            "Epoch 136/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0941 - accuracy: 0.6750 - val_loss: 1.0961 - val_accuracy: 0.6167\n",
            "Epoch 137/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0940 - accuracy: 0.6750 - val_loss: 1.0960 - val_accuracy: 0.6250\n",
            "Epoch 138/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0940 - accuracy: 0.6750 - val_loss: 1.0960 - val_accuracy: 0.6250\n",
            "Epoch 139/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0940 - accuracy: 0.6750 - val_loss: 1.0960 - val_accuracy: 0.6167\n",
            "Epoch 140/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0939 - accuracy: 0.6750 - val_loss: 1.0960 - val_accuracy: 0.6250\n",
            "Epoch 141/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0939 - accuracy: 0.6750 - val_loss: 1.0959 - val_accuracy: 0.6250\n",
            "Epoch 142/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0939 - accuracy: 0.6750 - val_loss: 1.0959 - val_accuracy: 0.6167\n",
            "Epoch 143/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0938 - accuracy: 0.6750 - val_loss: 1.0959 - val_accuracy: 0.6250\n",
            "Epoch 144/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0938 - accuracy: 0.6750 - val_loss: 1.0959 - val_accuracy: 0.6250\n",
            "Epoch 145/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0938 - accuracy: 0.6750 - val_loss: 1.0959 - val_accuracy: 0.6250\n",
            "Epoch 146/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0937 - accuracy: 0.6750 - val_loss: 1.0958 - val_accuracy: 0.6250\n",
            "Epoch 147/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0937 - accuracy: 0.6750 - val_loss: 1.0958 - val_accuracy: 0.6250\n",
            "Epoch 148/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0937 - accuracy: 0.6750 - val_loss: 1.0958 - val_accuracy: 0.6250\n",
            "Epoch 149/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0936 - accuracy: 0.6750 - val_loss: 1.0957 - val_accuracy: 0.6250\n",
            "Epoch 150/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0936 - accuracy: 0.6750 - val_loss: 1.0957 - val_accuracy: 0.6250\n",
            "Epoch 151/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0936 - accuracy: 0.6750 - val_loss: 1.0957 - val_accuracy: 0.6250\n",
            "Epoch 152/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0935 - accuracy: 0.6750 - val_loss: 1.0957 - val_accuracy: 0.6167\n",
            "Epoch 153/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0935 - accuracy: 0.6750 - val_loss: 1.0956 - val_accuracy: 0.6250\n",
            "Epoch 154/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0935 - accuracy: 0.6750 - val_loss: 1.0956 - val_accuracy: 0.6250\n",
            "Epoch 155/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0934 - accuracy: 0.6750 - val_loss: 1.0956 - val_accuracy: 0.6250\n",
            "Epoch 156/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0934 - accuracy: 0.6750 - val_loss: 1.0955 - val_accuracy: 0.6250\n",
            "Epoch 157/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0934 - accuracy: 0.6750 - val_loss: 1.0955 - val_accuracy: 0.6167\n",
            "Epoch 158/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0934 - accuracy: 0.6750 - val_loss: 1.0955 - val_accuracy: 0.6250\n",
            "Epoch 159/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0933 - accuracy: 0.6750 - val_loss: 1.0955 - val_accuracy: 0.6250\n",
            "Epoch 160/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0933 - accuracy: 0.6750 - val_loss: 1.0954 - val_accuracy: 0.6250\n",
            "Epoch 161/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0933 - accuracy: 0.6750 - val_loss: 1.0954 - val_accuracy: 0.6250\n",
            "Epoch 162/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0932 - accuracy: 0.6750 - val_loss: 1.0954 - val_accuracy: 0.6250\n",
            "Epoch 163/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0932 - accuracy: 0.6750 - val_loss: 1.0953 - val_accuracy: 0.6167\n",
            "Epoch 164/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0932 - accuracy: 0.6750 - val_loss: 1.0953 - val_accuracy: 0.6250\n",
            "Epoch 165/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0931 - accuracy: 0.6750 - val_loss: 1.0953 - val_accuracy: 0.6250\n",
            "Epoch 166/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0931 - accuracy: 0.6750 - val_loss: 1.0953 - val_accuracy: 0.6250\n",
            "Epoch 167/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0931 - accuracy: 0.6750 - val_loss: 1.0952 - val_accuracy: 0.6167\n",
            "Epoch 168/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0930 - accuracy: 0.6750 - val_loss: 1.0952 - val_accuracy: 0.6250\n",
            "Epoch 169/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0930 - accuracy: 0.6750 - val_loss: 1.0952 - val_accuracy: 0.6167\n",
            "Epoch 170/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0930 - accuracy: 0.6750 - val_loss: 1.0952 - val_accuracy: 0.6250\n",
            "Epoch 171/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0929 - accuracy: 0.6750 - val_loss: 1.0951 - val_accuracy: 0.6250\n",
            "Epoch 172/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0929 - accuracy: 0.6750 - val_loss: 1.0951 - val_accuracy: 0.6250\n",
            "Epoch 173/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0929 - accuracy: 0.6750 - val_loss: 1.0951 - val_accuracy: 0.6250\n",
            "Epoch 174/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0929 - accuracy: 0.6750 - val_loss: 1.0950 - val_accuracy: 0.6250\n",
            "Epoch 175/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0928 - accuracy: 0.6750 - val_loss: 1.0950 - val_accuracy: 0.6250\n",
            "Epoch 176/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0928 - accuracy: 0.6750 - val_loss: 1.0950 - val_accuracy: 0.6250\n",
            "Epoch 177/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0928 - accuracy: 0.6750 - val_loss: 1.0949 - val_accuracy: 0.6250\n",
            "Epoch 178/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0927 - accuracy: 0.6750 - val_loss: 1.0949 - val_accuracy: 0.6250\n",
            "Epoch 179/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0927 - accuracy: 0.6750 - val_loss: 1.0949 - val_accuracy: 0.6250\n",
            "Epoch 180/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0927 - accuracy: 0.6750 - val_loss: 1.0949 - val_accuracy: 0.6250\n",
            "Epoch 181/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0926 - accuracy: 0.6750 - val_loss: 1.0948 - val_accuracy: 0.6250\n",
            "Epoch 182/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0926 - accuracy: 0.6750 - val_loss: 1.0948 - val_accuracy: 0.6250\n",
            "Epoch 183/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0926 - accuracy: 0.6750 - val_loss: 1.0948 - val_accuracy: 0.6250\n",
            "Epoch 184/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0925 - accuracy: 0.6750 - val_loss: 1.0947 - val_accuracy: 0.6250\n",
            "Epoch 185/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0925 - accuracy: 0.6750 - val_loss: 1.0947 - val_accuracy: 0.6250\n",
            "Epoch 186/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0925 - accuracy: 0.6750 - val_loss: 1.0947 - val_accuracy: 0.6250\n",
            "Epoch 187/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0924 - accuracy: 0.6750 - val_loss: 1.0947 - val_accuracy: 0.6250\n",
            "Epoch 188/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0924 - accuracy: 0.6750 - val_loss: 1.0946 - val_accuracy: 0.6250\n",
            "Epoch 189/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0924 - accuracy: 0.6750 - val_loss: 1.0946 - val_accuracy: 0.6250\n",
            "Epoch 190/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0923 - accuracy: 0.6750 - val_loss: 1.0946 - val_accuracy: 0.6250\n",
            "Epoch 191/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0923 - accuracy: 0.6750 - val_loss: 1.0946 - val_accuracy: 0.6250\n",
            "Epoch 192/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0923 - accuracy: 0.6750 - val_loss: 1.0945 - val_accuracy: 0.6250\n",
            "Epoch 193/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0922 - accuracy: 0.6750 - val_loss: 1.0945 - val_accuracy: 0.6250\n",
            "Epoch 194/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0922 - accuracy: 0.6750 - val_loss: 1.0944 - val_accuracy: 0.6250\n",
            "Epoch 195/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0922 - accuracy: 0.6750 - val_loss: 1.0944 - val_accuracy: 0.6250\n",
            "Epoch 196/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0922 - accuracy: 0.6750 - val_loss: 1.0944 - val_accuracy: 0.6250\n",
            "Epoch 197/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0921 - accuracy: 0.6750 - val_loss: 1.0944 - val_accuracy: 0.6250\n",
            "Epoch 198/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0921 - accuracy: 0.6750 - val_loss: 1.0943 - val_accuracy: 0.6250\n",
            "Epoch 199/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0921 - accuracy: 0.6750 - val_loss: 1.0943 - val_accuracy: 0.6250\n",
            "Epoch 200/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0920 - accuracy: 0.6750 - val_loss: 1.0943 - val_accuracy: 0.6250\n",
            "Epoch 201/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0920 - accuracy: 0.6750 - val_loss: 1.0943 - val_accuracy: 0.6250\n",
            "Epoch 202/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0920 - accuracy: 0.6750 - val_loss: 1.0942 - val_accuracy: 0.6250\n",
            "Epoch 203/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0919 - accuracy: 0.6750 - val_loss: 1.0942 - val_accuracy: 0.6250\n",
            "Epoch 204/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0919 - accuracy: 0.6750 - val_loss: 1.0942 - val_accuracy: 0.6250\n",
            "Epoch 205/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0919 - accuracy: 0.6750 - val_loss: 1.0942 - val_accuracy: 0.6250\n",
            "Epoch 206/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0918 - accuracy: 0.6750 - val_loss: 1.0941 - val_accuracy: 0.6250\n",
            "Epoch 207/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0918 - accuracy: 0.6750 - val_loss: 1.0941 - val_accuracy: 0.6250\n",
            "Epoch 208/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0918 - accuracy: 0.6750 - val_loss: 1.0940 - val_accuracy: 0.6250\n",
            "Epoch 209/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0917 - accuracy: 0.6750 - val_loss: 1.0940 - val_accuracy: 0.6250\n",
            "Epoch 210/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0917 - accuracy: 0.6750 - val_loss: 1.0940 - val_accuracy: 0.6250\n",
            "Epoch 211/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0917 - accuracy: 0.6750 - val_loss: 1.0940 - val_accuracy: 0.6250\n",
            "Epoch 212/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0917 - accuracy: 0.6750 - val_loss: 1.0940 - val_accuracy: 0.6250\n",
            "Epoch 213/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0916 - accuracy: 0.6750 - val_loss: 1.0939 - val_accuracy: 0.6250\n",
            "Epoch 214/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0916 - accuracy: 0.6750 - val_loss: 1.0939 - val_accuracy: 0.6250\n",
            "Epoch 215/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0916 - accuracy: 0.6750 - val_loss: 1.0938 - val_accuracy: 0.6250\n",
            "Epoch 216/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0915 - accuracy: 0.6750 - val_loss: 1.0938 - val_accuracy: 0.6250\n",
            "Epoch 217/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0915 - accuracy: 0.6750 - val_loss: 1.0938 - val_accuracy: 0.6250\n",
            "Epoch 218/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0915 - accuracy: 0.6750 - val_loss: 1.0938 - val_accuracy: 0.6250\n",
            "Epoch 219/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0914 - accuracy: 0.6750 - val_loss: 1.0938 - val_accuracy: 0.6250\n",
            "Epoch 220/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0914 - accuracy: 0.6750 - val_loss: 1.0937 - val_accuracy: 0.6250\n",
            "Epoch 221/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0914 - accuracy: 0.6750 - val_loss: 1.0937 - val_accuracy: 0.6250\n",
            "Epoch 222/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0913 - accuracy: 0.6750 - val_loss: 1.0936 - val_accuracy: 0.6250\n",
            "Epoch 223/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0913 - accuracy: 0.6750 - val_loss: 1.0936 - val_accuracy: 0.6250\n",
            "Epoch 224/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0913 - accuracy: 0.6750 - val_loss: 1.0936 - val_accuracy: 0.6250\n",
            "Epoch 225/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0912 - accuracy: 0.6750 - val_loss: 1.0935 - val_accuracy: 0.6250\n",
            "Epoch 226/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0912 - accuracy: 0.6750 - val_loss: 1.0935 - val_accuracy: 0.6250\n",
            "Epoch 227/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0912 - accuracy: 0.6750 - val_loss: 1.0935 - val_accuracy: 0.6250\n",
            "Epoch 228/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0912 - accuracy: 0.6750 - val_loss: 1.0935 - val_accuracy: 0.6250\n",
            "Epoch 229/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0911 - accuracy: 0.6750 - val_loss: 1.0934 - val_accuracy: 0.6250\n",
            "Epoch 230/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0911 - accuracy: 0.6750 - val_loss: 1.0934 - val_accuracy: 0.6250\n",
            "Epoch 231/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0911 - accuracy: 0.6750 - val_loss: 1.0934 - val_accuracy: 0.6250\n",
            "Epoch 232/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0910 - accuracy: 0.6750 - val_loss: 1.0933 - val_accuracy: 0.6250\n",
            "Epoch 233/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0910 - accuracy: 0.6750 - val_loss: 1.0933 - val_accuracy: 0.6250\n",
            "Epoch 234/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0910 - accuracy: 0.6750 - val_loss: 1.0933 - val_accuracy: 0.6250\n",
            "Epoch 235/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0909 - accuracy: 0.6750 - val_loss: 1.0933 - val_accuracy: 0.6250\n",
            "Epoch 236/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0909 - accuracy: 0.6750 - val_loss: 1.0932 - val_accuracy: 0.6250\n",
            "Epoch 237/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0909 - accuracy: 0.6750 - val_loss: 1.0932 - val_accuracy: 0.6250\n",
            "Epoch 238/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0908 - accuracy: 0.6750 - val_loss: 1.0932 - val_accuracy: 0.6250\n",
            "Epoch 239/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0908 - accuracy: 0.6750 - val_loss: 1.0931 - val_accuracy: 0.6250\n",
            "Epoch 240/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0908 - accuracy: 0.6750 - val_loss: 1.0931 - val_accuracy: 0.6250\n",
            "Epoch 241/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0907 - accuracy: 0.6750 - val_loss: 1.0931 - val_accuracy: 0.6250\n",
            "Epoch 242/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0907 - accuracy: 0.6750 - val_loss: 1.0930 - val_accuracy: 0.6250\n",
            "Epoch 243/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0907 - accuracy: 0.6750 - val_loss: 1.0930 - val_accuracy: 0.6250\n",
            "Epoch 244/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0906 - accuracy: 0.6750 - val_loss: 1.0930 - val_accuracy: 0.6250\n",
            "Epoch 245/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0906 - accuracy: 0.6750 - val_loss: 1.0930 - val_accuracy: 0.6250\n",
            "Epoch 246/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0906 - accuracy: 0.6750 - val_loss: 1.0929 - val_accuracy: 0.6250\n",
            "Epoch 247/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0906 - accuracy: 0.6750 - val_loss: 1.0929 - val_accuracy: 0.6250\n",
            "Epoch 248/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0905 - accuracy: 0.6750 - val_loss: 1.0929 - val_accuracy: 0.6250\n",
            "Epoch 249/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0905 - accuracy: 0.6750 - val_loss: 1.0929 - val_accuracy: 0.6250\n",
            "Epoch 250/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0905 - accuracy: 0.6750 - val_loss: 1.0928 - val_accuracy: 0.6250\n",
            "Epoch 251/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0904 - accuracy: 0.6750 - val_loss: 1.0928 - val_accuracy: 0.6250\n",
            "Epoch 252/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0904 - accuracy: 0.6750 - val_loss: 1.0928 - val_accuracy: 0.6250\n",
            "Epoch 253/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0904 - accuracy: 0.6750 - val_loss: 1.0927 - val_accuracy: 0.6250\n",
            "Epoch 254/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0903 - accuracy: 0.6750 - val_loss: 1.0927 - val_accuracy: 0.6250\n",
            "Epoch 255/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0903 - accuracy: 0.6750 - val_loss: 1.0927 - val_accuracy: 0.6250\n",
            "Epoch 256/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0903 - accuracy: 0.6750 - val_loss: 1.0926 - val_accuracy: 0.6250\n",
            "Epoch 257/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0902 - accuracy: 0.6750 - val_loss: 1.0926 - val_accuracy: 0.6250\n",
            "Epoch 258/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0902 - accuracy: 0.6750 - val_loss: 1.0926 - val_accuracy: 0.6250\n",
            "Epoch 259/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0902 - accuracy: 0.6750 - val_loss: 1.0925 - val_accuracy: 0.6250\n",
            "Epoch 260/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0902 - accuracy: 0.6750 - val_loss: 1.0925 - val_accuracy: 0.6250\n",
            "Epoch 261/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0901 - accuracy: 0.6750 - val_loss: 1.0925 - val_accuracy: 0.6250\n",
            "Epoch 262/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0901 - accuracy: 0.6750 - val_loss: 1.0925 - val_accuracy: 0.6250\n",
            "Epoch 263/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0901 - accuracy: 0.6750 - val_loss: 1.0924 - val_accuracy: 0.6250\n",
            "Epoch 264/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0900 - accuracy: 0.6750 - val_loss: 1.0924 - val_accuracy: 0.6250\n",
            "Epoch 265/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0900 - accuracy: 0.6750 - val_loss: 1.0924 - val_accuracy: 0.6250\n",
            "Epoch 266/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0900 - accuracy: 0.6750 - val_loss: 1.0923 - val_accuracy: 0.6250\n",
            "Epoch 267/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0899 - accuracy: 0.6750 - val_loss: 1.0923 - val_accuracy: 0.6250\n",
            "Epoch 268/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0899 - accuracy: 0.6750 - val_loss: 1.0923 - val_accuracy: 0.6250\n",
            "Epoch 269/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0899 - accuracy: 0.6750 - val_loss: 1.0923 - val_accuracy: 0.6250\n",
            "Epoch 270/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0898 - accuracy: 0.6750 - val_loss: 1.0922 - val_accuracy: 0.6250\n",
            "Epoch 271/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0898 - accuracy: 0.6750 - val_loss: 1.0922 - val_accuracy: 0.6250\n",
            "Epoch 272/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0898 - accuracy: 0.6750 - val_loss: 1.0922 - val_accuracy: 0.6250\n",
            "Epoch 273/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0898 - accuracy: 0.6750 - val_loss: 1.0921 - val_accuracy: 0.6250\n",
            "Epoch 274/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0897 - accuracy: 0.6750 - val_loss: 1.0921 - val_accuracy: 0.6250\n",
            "Epoch 275/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0897 - accuracy: 0.6750 - val_loss: 1.0921 - val_accuracy: 0.6250\n",
            "Epoch 276/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0897 - accuracy: 0.6750 - val_loss: 1.0920 - val_accuracy: 0.6250\n",
            "Epoch 277/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0896 - accuracy: 0.6750 - val_loss: 1.0920 - val_accuracy: 0.6250\n",
            "Epoch 278/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0896 - accuracy: 0.6750 - val_loss: 1.0920 - val_accuracy: 0.6250\n",
            "Epoch 279/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0896 - accuracy: 0.6750 - val_loss: 1.0919 - val_accuracy: 0.6250\n",
            "Epoch 280/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0895 - accuracy: 0.6750 - val_loss: 1.0919 - val_accuracy: 0.6250\n",
            "Epoch 281/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0895 - accuracy: 0.6750 - val_loss: 1.0919 - val_accuracy: 0.6250\n",
            "Epoch 282/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0895 - accuracy: 0.6750 - val_loss: 1.0918 - val_accuracy: 0.6250\n",
            "Epoch 283/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0894 - accuracy: 0.6750 - val_loss: 1.0918 - val_accuracy: 0.6250\n",
            "Epoch 284/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0894 - accuracy: 0.6750 - val_loss: 1.0918 - val_accuracy: 0.6250\n",
            "Epoch 285/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0894 - accuracy: 0.6750 - val_loss: 1.0917 - val_accuracy: 0.6250\n",
            "Epoch 286/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0894 - accuracy: 0.6750 - val_loss: 1.0918 - val_accuracy: 0.6250\n",
            "Epoch 287/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0893 - accuracy: 0.6750 - val_loss: 1.0917 - val_accuracy: 0.6250\n",
            "Epoch 288/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0893 - accuracy: 0.6750 - val_loss: 1.0917 - val_accuracy: 0.6250\n",
            "Epoch 289/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0892 - accuracy: 0.6750 - val_loss: 1.0917 - val_accuracy: 0.6250\n",
            "Epoch 290/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0892 - accuracy: 0.6750 - val_loss: 1.0916 - val_accuracy: 0.6250\n",
            "Epoch 291/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0892 - accuracy: 0.6750 - val_loss: 1.0916 - val_accuracy: 0.6250\n",
            "Epoch 292/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0891 - accuracy: 0.6750 - val_loss: 1.0915 - val_accuracy: 0.6250\n",
            "Epoch 293/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0891 - accuracy: 0.6750 - val_loss: 1.0915 - val_accuracy: 0.6250\n",
            "Epoch 294/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0891 - accuracy: 0.6750 - val_loss: 1.0915 - val_accuracy: 0.6250\n",
            "Epoch 295/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0891 - accuracy: 0.6750 - val_loss: 1.0914 - val_accuracy: 0.6250\n",
            "Epoch 296/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0890 - accuracy: 0.6750 - val_loss: 1.0914 - val_accuracy: 0.6250\n",
            "Epoch 297/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0890 - accuracy: 0.6750 - val_loss: 1.0914 - val_accuracy: 0.6250\n",
            "Epoch 298/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0890 - accuracy: 0.6750 - val_loss: 1.0913 - val_accuracy: 0.6250\n",
            "Epoch 299/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0889 - accuracy: 0.6750 - val_loss: 1.0913 - val_accuracy: 0.6250\n",
            "Epoch 300/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0889 - accuracy: 0.6750 - val_loss: 1.0913 - val_accuracy: 0.6250\n",
            "Epoch 301/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0889 - accuracy: 0.6750 - val_loss: 1.0913 - val_accuracy: 0.6250\n",
            "Epoch 302/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0888 - accuracy: 0.6750 - val_loss: 1.0912 - val_accuracy: 0.6250\n",
            "Epoch 303/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0888 - accuracy: 0.6750 - val_loss: 1.0912 - val_accuracy: 0.6250\n",
            "Epoch 304/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0888 - accuracy: 0.6750 - val_loss: 1.0912 - val_accuracy: 0.6250\n",
            "Epoch 305/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0888 - accuracy: 0.6750 - val_loss: 1.0912 - val_accuracy: 0.6250\n",
            "Epoch 306/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0887 - accuracy: 0.6750 - val_loss: 1.0911 - val_accuracy: 0.6250\n",
            "Epoch 307/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0887 - accuracy: 0.6750 - val_loss: 1.0911 - val_accuracy: 0.6250\n",
            "Epoch 308/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0886 - accuracy: 0.6750 - val_loss: 1.0910 - val_accuracy: 0.6250\n",
            "Epoch 309/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0886 - accuracy: 0.6750 - val_loss: 1.0910 - val_accuracy: 0.6250\n",
            "Epoch 310/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0886 - accuracy: 0.6750 - val_loss: 1.0910 - val_accuracy: 0.6250\n",
            "Epoch 311/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0886 - accuracy: 0.6750 - val_loss: 1.0910 - val_accuracy: 0.6250\n",
            "Epoch 312/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0885 - accuracy: 0.6750 - val_loss: 1.0909 - val_accuracy: 0.6250\n",
            "Epoch 313/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0885 - accuracy: 0.6750 - val_loss: 1.0909 - val_accuracy: 0.6250\n",
            "Epoch 314/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0885 - accuracy: 0.6750 - val_loss: 1.0909 - val_accuracy: 0.6250\n",
            "Epoch 315/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0884 - accuracy: 0.6750 - val_loss: 1.0908 - val_accuracy: 0.6250\n",
            "Epoch 316/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0884 - accuracy: 0.6750 - val_loss: 1.0908 - val_accuracy: 0.6250\n",
            "Epoch 317/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0884 - accuracy: 0.6750 - val_loss: 1.0908 - val_accuracy: 0.6250\n",
            "Epoch 318/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0883 - accuracy: 0.6750 - val_loss: 1.0907 - val_accuracy: 0.6250\n",
            "Epoch 319/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0883 - accuracy: 0.6750 - val_loss: 1.0907 - val_accuracy: 0.6250\n",
            "Epoch 320/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0883 - accuracy: 0.6750 - val_loss: 1.0907 - val_accuracy: 0.6250\n",
            "Epoch 321/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0882 - accuracy: 0.6750 - val_loss: 1.0906 - val_accuracy: 0.6250\n",
            "Epoch 322/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0882 - accuracy: 0.6750 - val_loss: 1.0906 - val_accuracy: 0.6250\n",
            "Epoch 323/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0882 - accuracy: 0.6750 - val_loss: 1.0906 - val_accuracy: 0.6250\n",
            "Epoch 324/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0882 - accuracy: 0.6750 - val_loss: 1.0906 - val_accuracy: 0.6250\n",
            "Epoch 325/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0881 - accuracy: 0.6750 - val_loss: 1.0905 - val_accuracy: 0.6250\n",
            "Epoch 326/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0881 - accuracy: 0.6750 - val_loss: 1.0905 - val_accuracy: 0.6250\n",
            "Epoch 327/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0881 - accuracy: 0.6750 - val_loss: 1.0905 - val_accuracy: 0.6250\n",
            "Epoch 328/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0880 - accuracy: 0.6750 - val_loss: 1.0904 - val_accuracy: 0.6250\n",
            "Epoch 329/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0880 - accuracy: 0.6750 - val_loss: 1.0904 - val_accuracy: 0.6250\n",
            "Epoch 330/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0880 - accuracy: 0.6750 - val_loss: 1.0904 - val_accuracy: 0.6250\n",
            "Epoch 331/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0879 - accuracy: 0.6750 - val_loss: 1.0904 - val_accuracy: 0.6250\n",
            "Epoch 332/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0879 - accuracy: 0.6750 - val_loss: 1.0903 - val_accuracy: 0.6250\n",
            "Epoch 333/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0879 - accuracy: 0.6750 - val_loss: 1.0903 - val_accuracy: 0.6250\n",
            "Epoch 334/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0878 - accuracy: 0.6750 - val_loss: 1.0903 - val_accuracy: 0.6250\n",
            "Epoch 335/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0878 - accuracy: 0.6750 - val_loss: 1.0902 - val_accuracy: 0.6250\n",
            "Epoch 336/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0878 - accuracy: 0.6750 - val_loss: 1.0902 - val_accuracy: 0.6250\n",
            "Epoch 337/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0877 - accuracy: 0.6750 - val_loss: 1.0902 - val_accuracy: 0.6250\n",
            "Epoch 338/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0877 - accuracy: 0.6750 - val_loss: 1.0901 - val_accuracy: 0.6250\n",
            "Epoch 339/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0877 - accuracy: 0.6750 - val_loss: 1.0901 - val_accuracy: 0.6250\n",
            "Epoch 340/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0876 - accuracy: 0.6750 - val_loss: 1.0901 - val_accuracy: 0.6250\n",
            "Epoch 341/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0876 - accuracy: 0.6750 - val_loss: 1.0901 - val_accuracy: 0.6250\n",
            "Epoch 342/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0876 - accuracy: 0.6750 - val_loss: 1.0900 - val_accuracy: 0.6250\n",
            "Epoch 343/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0876 - accuracy: 0.6750 - val_loss: 1.0900 - val_accuracy: 0.6250\n",
            "Epoch 344/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0876 - accuracy: 0.6750 - val_loss: 1.0900 - val_accuracy: 0.6250\n",
            "Epoch 345/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0875 - accuracy: 0.6750 - val_loss: 1.0899 - val_accuracy: 0.6250\n",
            "Epoch 346/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0875 - accuracy: 0.6750 - val_loss: 1.0899 - val_accuracy: 0.6250\n",
            "Epoch 347/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0874 - accuracy: 0.6750 - val_loss: 1.0899 - val_accuracy: 0.6250\n",
            "Epoch 348/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0874 - accuracy: 0.6750 - val_loss: 1.0898 - val_accuracy: 0.6250\n",
            "Epoch 349/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0874 - accuracy: 0.6750 - val_loss: 1.0898 - val_accuracy: 0.6250\n",
            "Epoch 350/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0873 - accuracy: 0.6750 - val_loss: 1.0898 - val_accuracy: 0.6250\n",
            "Epoch 351/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0873 - accuracy: 0.6750 - val_loss: 1.0898 - val_accuracy: 0.6250\n",
            "Epoch 352/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0873 - accuracy: 0.6750 - val_loss: 1.0897 - val_accuracy: 0.6250\n",
            "Epoch 353/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0872 - accuracy: 0.6750 - val_loss: 1.0897 - val_accuracy: 0.6250\n",
            "Epoch 354/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0872 - accuracy: 0.6750 - val_loss: 1.0897 - val_accuracy: 0.6250\n",
            "Epoch 355/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0872 - accuracy: 0.6750 - val_loss: 1.0896 - val_accuracy: 0.6250\n",
            "Epoch 356/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0872 - accuracy: 0.6750 - val_loss: 1.0896 - val_accuracy: 0.6250\n",
            "Epoch 357/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0871 - accuracy: 0.6750 - val_loss: 1.0895 - val_accuracy: 0.6250\n",
            "Epoch 358/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0871 - accuracy: 0.6750 - val_loss: 1.0895 - val_accuracy: 0.6250\n",
            "Epoch 359/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0871 - accuracy: 0.6750 - val_loss: 1.0895 - val_accuracy: 0.6250\n",
            "Epoch 360/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0870 - accuracy: 0.6750 - val_loss: 1.0895 - val_accuracy: 0.6250\n",
            "Epoch 361/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0870 - accuracy: 0.6750 - val_loss: 1.0894 - val_accuracy: 0.6250\n",
            "Epoch 362/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0870 - accuracy: 0.6750 - val_loss: 1.0894 - val_accuracy: 0.6250\n",
            "Epoch 363/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0869 - accuracy: 0.6750 - val_loss: 1.0894 - val_accuracy: 0.6250\n",
            "Epoch 364/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0869 - accuracy: 0.6750 - val_loss: 1.0893 - val_accuracy: 0.6250\n",
            "Epoch 365/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0869 - accuracy: 0.6750 - val_loss: 1.0893 - val_accuracy: 0.6250\n",
            "Epoch 366/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0868 - accuracy: 0.6750 - val_loss: 1.0893 - val_accuracy: 0.6250\n",
            "Epoch 367/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0868 - accuracy: 0.6750 - val_loss: 1.0893 - val_accuracy: 0.6250\n",
            "Epoch 368/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0868 - accuracy: 0.6750 - val_loss: 1.0892 - val_accuracy: 0.6250\n",
            "Epoch 369/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0867 - accuracy: 0.6750 - val_loss: 1.0892 - val_accuracy: 0.6250\n",
            "Epoch 370/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0867 - accuracy: 0.6750 - val_loss: 1.0892 - val_accuracy: 0.6250\n",
            "Epoch 371/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0867 - accuracy: 0.6750 - val_loss: 1.0891 - val_accuracy: 0.6250\n",
            "Epoch 372/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0867 - accuracy: 0.6750 - val_loss: 1.0891 - val_accuracy: 0.6250\n",
            "Epoch 373/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0866 - accuracy: 0.6750 - val_loss: 1.0891 - val_accuracy: 0.6250\n",
            "Epoch 374/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0866 - accuracy: 0.6750 - val_loss: 1.0890 - val_accuracy: 0.6250\n",
            "Epoch 375/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0866 - accuracy: 0.6750 - val_loss: 1.0890 - val_accuracy: 0.6250\n",
            "Epoch 376/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0865 - accuracy: 0.6750 - val_loss: 1.0890 - val_accuracy: 0.6250\n",
            "Epoch 377/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0865 - accuracy: 0.6750 - val_loss: 1.0889 - val_accuracy: 0.6250\n",
            "Epoch 378/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0865 - accuracy: 0.6750 - val_loss: 1.0889 - val_accuracy: 0.6250\n",
            "Epoch 379/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0864 - accuracy: 0.6750 - val_loss: 1.0889 - val_accuracy: 0.6250\n",
            "Epoch 380/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0864 - accuracy: 0.6750 - val_loss: 1.0888 - val_accuracy: 0.6250\n",
            "Epoch 381/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0864 - accuracy: 0.6750 - val_loss: 1.0888 - val_accuracy: 0.6250\n",
            "Epoch 382/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0863 - accuracy: 0.6750 - val_loss: 1.0888 - val_accuracy: 0.6250\n",
            "Epoch 383/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0863 - accuracy: 0.6750 - val_loss: 1.0888 - val_accuracy: 0.6250\n",
            "Epoch 384/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0863 - accuracy: 0.6750 - val_loss: 1.0887 - val_accuracy: 0.6250\n",
            "Epoch 385/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0862 - accuracy: 0.6750 - val_loss: 1.0887 - val_accuracy: 0.6250\n",
            "Epoch 386/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0862 - accuracy: 0.6750 - val_loss: 1.0887 - val_accuracy: 0.6250\n",
            "Epoch 387/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0862 - accuracy: 0.6750 - val_loss: 1.0886 - val_accuracy: 0.6250\n",
            "Epoch 388/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0861 - accuracy: 0.6750 - val_loss: 1.0886 - val_accuracy: 0.6250\n",
            "Epoch 389/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0861 - accuracy: 0.6750 - val_loss: 1.0886 - val_accuracy: 0.6250\n",
            "Epoch 390/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0861 - accuracy: 0.6750 - val_loss: 1.0885 - val_accuracy: 0.6250\n",
            "Epoch 391/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0861 - accuracy: 0.6750 - val_loss: 1.0885 - val_accuracy: 0.6250\n",
            "Epoch 392/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0860 - accuracy: 0.6750 - val_loss: 1.0885 - val_accuracy: 0.6250\n",
            "Epoch 393/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0860 - accuracy: 0.6750 - val_loss: 1.0884 - val_accuracy: 0.6250\n",
            "Epoch 394/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0860 - accuracy: 0.6750 - val_loss: 1.0884 - val_accuracy: 0.6250\n",
            "Epoch 395/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0859 - accuracy: 0.6750 - val_loss: 1.0884 - val_accuracy: 0.6250\n",
            "Epoch 396/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0859 - accuracy: 0.6750 - val_loss: 1.0883 - val_accuracy: 0.6250\n",
            "Epoch 397/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0859 - accuracy: 0.6750 - val_loss: 1.0883 - val_accuracy: 0.6250\n",
            "Epoch 398/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0858 - accuracy: 0.6750 - val_loss: 1.0883 - val_accuracy: 0.6250\n",
            "Epoch 399/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0858 - accuracy: 0.6750 - val_loss: 1.0883 - val_accuracy: 0.6250\n",
            "Epoch 400/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0858 - accuracy: 0.6750 - val_loss: 1.0882 - val_accuracy: 0.6250\n",
            "Epoch 401/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0857 - accuracy: 0.6750 - val_loss: 1.0882 - val_accuracy: 0.6250\n",
            "Epoch 402/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0857 - accuracy: 0.6750 - val_loss: 1.0881 - val_accuracy: 0.6250\n",
            "Epoch 403/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0857 - accuracy: 0.6750 - val_loss: 1.0881 - val_accuracy: 0.6250\n",
            "Epoch 404/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0856 - accuracy: 0.6750 - val_loss: 1.0881 - val_accuracy: 0.6250\n",
            "Epoch 405/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0856 - accuracy: 0.6750 - val_loss: 1.0880 - val_accuracy: 0.6250\n",
            "Epoch 406/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0856 - accuracy: 0.6750 - val_loss: 1.0880 - val_accuracy: 0.6250\n",
            "Epoch 407/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0856 - accuracy: 0.6750 - val_loss: 1.0880 - val_accuracy: 0.6250\n",
            "Epoch 408/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0855 - accuracy: 0.6750 - val_loss: 1.0880 - val_accuracy: 0.6250\n",
            "Epoch 409/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0855 - accuracy: 0.6750 - val_loss: 1.0880 - val_accuracy: 0.6250\n",
            "Epoch 410/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0855 - accuracy: 0.6750 - val_loss: 1.0879 - val_accuracy: 0.6250\n",
            "Epoch 411/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0854 - accuracy: 0.6750 - val_loss: 1.0879 - val_accuracy: 0.6250\n",
            "Epoch 412/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0854 - accuracy: 0.6750 - val_loss: 1.0879 - val_accuracy: 0.6250\n",
            "Epoch 413/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0854 - accuracy: 0.6750 - val_loss: 1.0878 - val_accuracy: 0.6250\n",
            "Epoch 414/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0853 - accuracy: 0.6750 - val_loss: 1.0878 - val_accuracy: 0.6250\n",
            "Epoch 415/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0853 - accuracy: 0.6750 - val_loss: 1.0878 - val_accuracy: 0.6250\n",
            "Epoch 416/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0853 - accuracy: 0.6750 - val_loss: 1.0877 - val_accuracy: 0.6250\n",
            "Epoch 417/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0852 - accuracy: 0.6750 - val_loss: 1.0877 - val_accuracy: 0.6250\n",
            "Epoch 418/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0852 - accuracy: 0.6750 - val_loss: 1.0877 - val_accuracy: 0.6250\n",
            "Epoch 419/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0852 - accuracy: 0.6750 - val_loss: 1.0876 - val_accuracy: 0.6250\n",
            "Epoch 420/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0852 - accuracy: 0.6750 - val_loss: 1.0876 - val_accuracy: 0.6250\n",
            "Epoch 421/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0851 - accuracy: 0.6750 - val_loss: 1.0876 - val_accuracy: 0.6250\n",
            "Epoch 422/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0851 - accuracy: 0.6750 - val_loss: 1.0875 - val_accuracy: 0.6250\n",
            "Epoch 423/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0851 - accuracy: 0.6750 - val_loss: 1.0875 - val_accuracy: 0.6250\n",
            "Epoch 424/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0850 - accuracy: 0.6750 - val_loss: 1.0875 - val_accuracy: 0.6250\n",
            "Epoch 425/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0850 - accuracy: 0.6750 - val_loss: 1.0875 - val_accuracy: 0.6250\n",
            "Epoch 426/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0850 - accuracy: 0.6750 - val_loss: 1.0874 - val_accuracy: 0.6250\n",
            "Epoch 427/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0849 - accuracy: 0.6750 - val_loss: 1.0874 - val_accuracy: 0.6250\n",
            "Epoch 428/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0849 - accuracy: 0.6750 - val_loss: 1.0874 - val_accuracy: 0.6250\n",
            "Epoch 429/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0849 - accuracy: 0.6750 - val_loss: 1.0873 - val_accuracy: 0.6250\n",
            "Epoch 430/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0848 - accuracy: 0.6750 - val_loss: 1.0873 - val_accuracy: 0.6250\n",
            "Epoch 431/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0848 - accuracy: 0.6750 - val_loss: 1.0873 - val_accuracy: 0.6250\n",
            "Epoch 432/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0848 - accuracy: 0.6750 - val_loss: 1.0872 - val_accuracy: 0.6250\n",
            "Epoch 433/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0848 - accuracy: 0.6750 - val_loss: 1.0872 - val_accuracy: 0.6250\n",
            "Epoch 434/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0847 - accuracy: 0.6750 - val_loss: 1.0872 - val_accuracy: 0.6250\n",
            "Epoch 435/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0847 - accuracy: 0.6750 - val_loss: 1.0871 - val_accuracy: 0.6250\n",
            "Epoch 436/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0847 - accuracy: 0.6750 - val_loss: 1.0871 - val_accuracy: 0.6250\n",
            "Epoch 437/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0846 - accuracy: 0.6750 - val_loss: 1.0871 - val_accuracy: 0.6250\n",
            "Epoch 438/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0846 - accuracy: 0.6750 - val_loss: 1.0871 - val_accuracy: 0.6250\n",
            "Epoch 439/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0846 - accuracy: 0.6750 - val_loss: 1.0870 - val_accuracy: 0.6250\n",
            "Epoch 440/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0846 - accuracy: 0.6750 - val_loss: 1.0870 - val_accuracy: 0.6250\n",
            "Epoch 441/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0845 - accuracy: 0.6750 - val_loss: 1.0870 - val_accuracy: 0.6250\n",
            "Epoch 442/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0845 - accuracy: 0.6750 - val_loss: 1.0869 - val_accuracy: 0.6250\n",
            "Epoch 443/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0844 - accuracy: 0.6750 - val_loss: 1.0869 - val_accuracy: 0.6250\n",
            "Epoch 444/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0844 - accuracy: 0.6750 - val_loss: 1.0869 - val_accuracy: 0.6250\n",
            "Epoch 445/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0844 - accuracy: 0.6750 - val_loss: 1.0868 - val_accuracy: 0.6250\n",
            "Epoch 446/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0844 - accuracy: 0.6750 - val_loss: 1.0868 - val_accuracy: 0.6250\n",
            "Epoch 447/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0843 - accuracy: 0.6750 - val_loss: 1.0868 - val_accuracy: 0.6250\n",
            "Epoch 448/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0843 - accuracy: 0.6750 - val_loss: 1.0868 - val_accuracy: 0.6250\n",
            "Epoch 449/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0843 - accuracy: 0.6750 - val_loss: 1.0867 - val_accuracy: 0.6250\n",
            "Epoch 450/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0842 - accuracy: 0.6750 - val_loss: 1.0867 - val_accuracy: 0.6250\n",
            "Epoch 451/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0842 - accuracy: 0.6750 - val_loss: 1.0867 - val_accuracy: 0.6250\n",
            "Epoch 452/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0842 - accuracy: 0.6750 - val_loss: 1.0866 - val_accuracy: 0.6250\n",
            "Epoch 453/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0841 - accuracy: 0.6750 - val_loss: 1.0866 - val_accuracy: 0.6250\n",
            "Epoch 454/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0841 - accuracy: 0.6750 - val_loss: 1.0866 - val_accuracy: 0.6250\n",
            "Epoch 455/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0841 - accuracy: 0.6750 - val_loss: 1.0865 - val_accuracy: 0.6250\n",
            "Epoch 456/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0840 - accuracy: 0.6750 - val_loss: 1.0865 - val_accuracy: 0.6250\n",
            "Epoch 457/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0840 - accuracy: 0.6750 - val_loss: 1.0865 - val_accuracy: 0.6250\n",
            "Epoch 458/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0840 - accuracy: 0.6750 - val_loss: 1.0864 - val_accuracy: 0.6250\n",
            "Epoch 459/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0840 - accuracy: 0.6750 - val_loss: 1.0864 - val_accuracy: 0.6250\n",
            "Epoch 460/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0839 - accuracy: 0.6750 - val_loss: 1.0864 - val_accuracy: 0.6250\n",
            "Epoch 461/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0839 - accuracy: 0.6750 - val_loss: 1.0863 - val_accuracy: 0.6250\n",
            "Epoch 462/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0839 - accuracy: 0.6750 - val_loss: 1.0863 - val_accuracy: 0.6250\n",
            "Epoch 463/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0838 - accuracy: 0.6750 - val_loss: 1.0863 - val_accuracy: 0.6250\n",
            "Epoch 464/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0838 - accuracy: 0.6750 - val_loss: 1.0863 - val_accuracy: 0.6250\n",
            "Epoch 465/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0838 - accuracy: 0.6750 - val_loss: 1.0862 - val_accuracy: 0.6250\n",
            "Epoch 466/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0837 - accuracy: 0.6750 - val_loss: 1.0862 - val_accuracy: 0.6250\n",
            "Epoch 467/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0837 - accuracy: 0.6750 - val_loss: 1.0862 - val_accuracy: 0.6250\n",
            "Epoch 468/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0837 - accuracy: 0.6750 - val_loss: 1.0861 - val_accuracy: 0.6250\n",
            "Epoch 469/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0836 - accuracy: 0.6750 - val_loss: 1.0861 - val_accuracy: 0.6250\n",
            "Epoch 470/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0836 - accuracy: 0.6750 - val_loss: 1.0861 - val_accuracy: 0.6250\n",
            "Epoch 471/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0836 - accuracy: 0.6750 - val_loss: 1.0861 - val_accuracy: 0.6250\n",
            "Epoch 472/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0836 - accuracy: 0.6750 - val_loss: 1.0860 - val_accuracy: 0.6250\n",
            "Epoch 473/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0835 - accuracy: 0.6750 - val_loss: 1.0860 - val_accuracy: 0.6250\n",
            "Epoch 474/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0835 - accuracy: 0.6750 - val_loss: 1.0860 - val_accuracy: 0.6250\n",
            "Epoch 475/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0835 - accuracy: 0.6750 - val_loss: 1.0859 - val_accuracy: 0.6250\n",
            "Epoch 476/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0834 - accuracy: 0.6750 - val_loss: 1.0859 - val_accuracy: 0.6250\n",
            "Epoch 477/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0834 - accuracy: 0.6750 - val_loss: 1.0858 - val_accuracy: 0.6250\n",
            "Epoch 478/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0834 - accuracy: 0.6750 - val_loss: 1.0858 - val_accuracy: 0.6250\n",
            "Epoch 479/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0833 - accuracy: 0.6750 - val_loss: 1.0858 - val_accuracy: 0.6250\n",
            "Epoch 480/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0833 - accuracy: 0.6750 - val_loss: 1.0858 - val_accuracy: 0.6250\n",
            "Epoch 481/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0833 - accuracy: 0.6750 - val_loss: 1.0857 - val_accuracy: 0.6250\n",
            "Epoch 482/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0833 - accuracy: 0.6750 - val_loss: 1.0857 - val_accuracy: 0.6250\n",
            "Epoch 483/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0832 - accuracy: 0.6750 - val_loss: 1.0857 - val_accuracy: 0.6250\n",
            "Epoch 484/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0832 - accuracy: 0.6750 - val_loss: 1.0856 - val_accuracy: 0.6250\n",
            "Epoch 485/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0832 - accuracy: 0.6750 - val_loss: 1.0856 - val_accuracy: 0.6250\n",
            "Epoch 486/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0831 - accuracy: 0.6750 - val_loss: 1.0856 - val_accuracy: 0.6250\n",
            "Epoch 487/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0831 - accuracy: 0.6750 - val_loss: 1.0856 - val_accuracy: 0.6250\n",
            "Epoch 488/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0831 - accuracy: 0.6750 - val_loss: 1.0855 - val_accuracy: 0.6250\n",
            "Epoch 489/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0830 - accuracy: 0.6750 - val_loss: 1.0855 - val_accuracy: 0.6250\n",
            "Epoch 490/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0830 - accuracy: 0.6750 - val_loss: 1.0854 - val_accuracy: 0.6250\n",
            "Epoch 491/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0830 - accuracy: 0.6750 - val_loss: 1.0854 - val_accuracy: 0.6250\n",
            "Epoch 492/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0829 - accuracy: 0.6750 - val_loss: 1.0854 - val_accuracy: 0.6250\n",
            "Epoch 493/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0829 - accuracy: 0.6750 - val_loss: 1.0854 - val_accuracy: 0.6250\n",
            "Epoch 494/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0829 - accuracy: 0.6750 - val_loss: 1.0854 - val_accuracy: 0.6250\n",
            "Epoch 495/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0829 - accuracy: 0.6750 - val_loss: 1.0853 - val_accuracy: 0.6250\n",
            "Epoch 496/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0828 - accuracy: 0.6750 - val_loss: 1.0853 - val_accuracy: 0.6250\n",
            "Epoch 497/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0828 - accuracy: 0.6750 - val_loss: 1.0852 - val_accuracy: 0.6250\n",
            "Epoch 498/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0828 - accuracy: 0.6750 - val_loss: 1.0852 - val_accuracy: 0.6250\n",
            "Epoch 499/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0827 - accuracy: 0.6750 - val_loss: 1.0852 - val_accuracy: 0.6250\n",
            "Epoch 500/500\n",
            "480/480 [==============================] - 6s 12ms/step - loss: 1.0827 - accuracy: 0.6750 - val_loss: 1.0852 - val_accuracy: 0.6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdFmvINernc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "1a5f76b5-fea8-422c-bdb5-37a606f77d0a"
      },
      "source": [
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdrdegeyr7UH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "3ebd6552-c1f6-4cf8-a7fa-626c87d24071"
      },
      "source": [
        "result = CNN_model.evaluate(x_train, y_train)\n",
        "print('train loss, train acc:', result)\n",
        "result2 = CNN_model.evaluate(x_test, y_test)\n",
        "print('test loss, test acc:', result2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "480/480 [==============================] - 5s 10ms/step\n",
            "train loss, train acc: [1.082673152287801, 0.675000011920929]\n",
            "120/120 [==============================] - 1s 10ms/step\n",
            "test loss, test acc: [1.085159722963969, 0.625]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpo9dRIRtUsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73d5b49a-de84-470d-cc6b-c0e593c624f7"
      },
      "source": [
        "# serialize model to YAML\n",
        "model_yaml = CNN_model.to_yaml()\n",
        "with open(\"model.yaml\", \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "# serialize weights to HDF5\n",
        "CNN_model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL7kC0y2tCSy",
        "colab_type": "text"
      },
      "source": [
        "Prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js3967KzsEvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "outputId": "8a594f4a-0f99-41df-f4f7-be7a72ced104"
      },
      "source": [
        "use_samples = [1, 2, 3, 4]\n",
        "samples_to_predict = []\n",
        "# Generate plots for samples\n",
        "for sample in use_samples:\n",
        "  # Generate a plot\n",
        "  reshaped_image = x_train[sample]\n",
        "  samples_to_predict.append(reshaped_image)\n",
        "  cv2_imshow(reshaped_image)\n",
        "samples_to_predict = np.asarray(samples_to_predict)\n",
        "predictions = CNN_model.predict(samples_to_predict)\n",
        "classes = np.argmax(predictions, axis = 1)\n",
        "pred_labels = classes\n",
        "print(classes)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAIAAACVT/22AAAAsUlEQVR4nO3OMQ0AAAgDsM2/aSRwEpJWQRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgE3b6wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDKAGnpAARYwCCmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=224x224 at 0x7FDB1E9324E0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAIAAACVT/22AAAAqUlEQVR4nO3BMQEAAADCoPVPbQlPoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAvgZM/gABE/clzwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=224x224 at 0x7FDB1E9323C8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAIAAACVT/22AAAAqUlEQVR4nO3BMQEAAADCoPVPbQlPoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAvgZM/gABE/clzwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=224x224 at 0x7FDB1E9324E0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAIAAACVT/22AAAAqUlEQVR4nO3BMQEAAADCoPVPbQlPoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAvgZM/gABE/clzwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=224x224 at 0x7FDB1E9323C8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldhNExTstOf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "21ca773a-1900-404c-95a4-6fca9d676ec8"
      },
      "source": [
        "for i in use_samples:\n",
        "    count=0\n",
        "    for j in y_train[i]:\n",
        "      if j==1:\n",
        "        print(count)\n",
        "        break\n",
        "      else:\n",
        "        count+=1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "2\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}